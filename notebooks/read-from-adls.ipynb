{"cells":[{"cell_type":"markdown","source":["##Load data from ADLS (Azure DataLake Storage)\nAdd your credentials from your Storage Account (ADLS)"],"metadata":{}},{"cell_type":"code","source":["STORAGE_ACCOUNT_NAME = '<YOUR_STORAGE_ACCOUNT>'\nCONTAINER_INPUT_RAW = '<YOUR_CONTAINER_RAW>'\nCONTAINER_INPUT_TABLES = '<YOUR_CONTAINER_TABLES>'\nKEY = '<YOUR_KEY>'"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":["##Mount ADLS\nWe will mount two folders (input and output files)"],"metadata":{}},{"cell_type":"code","source":["dbutils.fs.mount(\n  source = \"wasbs://{}@{}.blob.core.windows.net\".format(CONTAINER_INPUT_RAW, STORAGE_ACCOUNT_NAME),\n  mount_point = \"/mnt/{}\".format(CONTAINER_INPUT_RAW),\n  extra_configs = {\"fs.azure.account.key.{}.blob.core.windows.net\".format(STORAGE_ACCOUNT_NAME):\"{}\".format(KEY)})"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["dbutils.fs.mount(\n  source = \"wasbs://{}@{}.blob.core.windows.net\".format(CONTAINER_INPUT_TABLES, STORAGE_ACCOUNT_NAME),\n  mount_point = \"/mnt/{}\".format(CONTAINER_INPUT_TABLES),\n  extra_configs = {\"fs.azure.account.key.{}.blob.core.windows.net\".format(STORAGE_ACCOUNT_NAME):\"{}\".format(KEY)})"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["##Read from ADLS to Spark\nGet data from ADLS and transform to Spark DataFrame"],"metadata":{}},{"cell_type":"code","source":["FILENAME = \"/mnt/{}/UsedCars.csv\".format(CONTAINER_INPUT_RAW)\n\nUsedCars = (spark\n  .read\n  .option(\"header\", True)\n  .option(\"header\", True) \\\n  .option(\"sep\", ',') \\\n  .csv(FILENAME)\n)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["display(UsedCars)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["##Create a temporary table\nWe can create a table from Spark Dataframe to be able to use Spark SQL."],"metadata":{}},{"cell_type":"code","source":["temp_table_name = \"UsedCars_temp\"\n\nUsedCars.createOrReplaceGlobalTempView(temp_table_name)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["##Persist to a Permanent Table\nTo share to all notebooks and users we can choose to persist the Spark Dataframe to a permanent table. In this case we have two options, persist as a **Managed Table** or **Unmanaged Table**. The differences between these two options can be found in this [link](https://docs.databricks.com/data/tables.html#managed-and-unmanaged-tables&language-python). *In almost all use cases, UNmanaged tables are preferred.*"],"metadata":{}},{"cell_type":"markdown","source":["###Create a managed table"],"metadata":{}},{"cell_type":"code","source":["permanent_table_name = \"usedcars_managed\"\nUsedCars.write.saveAsTable(permanent_table_name)"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["###Create a unmanaged table"],"metadata":{}},{"cell_type":"code","source":["permanent_table_name = \"usedcars_unmanaged\"\nUsedCars.write.option('path', \"/mnt/tables/\").saveAsTable(permanent_table_name)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":["##Unmount if necessary"],"metadata":{}},{"cell_type":"code","source":["dbutils.fs.ls('/mnt/')\n#CONTAINER = 'cleaneddata'\n#dbutils.fs.unmount(\"/mnt/{}\".format(CONTAINER))"],"metadata":{},"outputs":[],"execution_count":17}],"metadata":{"name":"ml-persist-to-adls","notebookId":3418276086377745},"nbformat":4,"nbformat_minor":0}