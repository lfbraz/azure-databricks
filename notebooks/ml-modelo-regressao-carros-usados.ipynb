{"cells":[{"cell_type":"markdown","source":["#Machine Learning\n###Exemplo de modelo de regress√£o p/ previs√£o de pre√ßos de venda de carros usados\n* Este tutorial foi inspirado no treinamento de Cientista de Dados do [MS Learn](https://docs.microsoft.com/en-us/learn/). Algumas partes foram traduzidas para facilitar o entendimento, por√©m sugiro fortemente que todos realizem o treinamento oficial para um aprendizado mais aprofundado das t√©cnicas que ser√£o demonstradas aqui.\n\nFique a vontade para utilizar e adaptar conforme sua necessidade (ou divertimento üòé)."],"metadata":{}},{"cell_type":"markdown","source":["### Neste tutorial faremos uma [regress√£o linear simples](https://pt.wikipedia.org/wiki/Regress%C3%A3o_linear_simples) em que o objetivo ser√° prever o PRE√áO (y) de venda de um determinado modelo de ve√≠culo se baseando em algumas vari√°veis de entrada (X) \n\nA base de dados utilizada pode ser obtida no [link](https://github.com/lfbraz/machine-learning-tutorial/blob/master/datasets/dataset-carros-usados.csv) e foi baseada na vers√£o [original](https://databricksdemostore.blob.core.windows.net/data/02.02/UsedCars.csv) disponibilizada pela Databricks, em que foi adaptada e traduzida para Portugu√™s-Brasil."],"metadata":{}},{"cell_type":"markdown","source":["##Importar base de dados\nUtilizarei o [Azure Databricks](https://azure.microsoft.com/pt-br/services/databricks/) para treino do modelo, por√©m este tutorial pode ser utilizado com qualquer plataforma (sendo necess√°rio apenas que o m√©todo de importa√ß√£o seja adaptado).\n\nRealizamos o download do dataset utilizando a biblioteca [`requests`](https://pypi.org/project/requests/)."],"metadata":{}},{"cell_type":"code","source":["import requests\n\nfilename = \"dataset-carros-usados.csv\"\nurl = \"https://raw.githubusercontent.com/lfbraz/machine-learning-tutorial/master/datasets/{}\".format(filename)\noutput_local_file_path = \"/tmp/{}\".format(filename)\noutput_dbfs_file_path = \"/data/{}\".format(filename)\n\nprint('Fazendo o download de: {} para o diret√≥rio {}'.format(url, output_local_file_path))\n\n# Baixar e persistir o arquivo\nfile = requests.get(url)\nopen(output_local_file_path, 'wb').write(file.content)\n\n# Copiar para a estrutura de arquivos do Databricks\ndbutils.fs.cp(\"file:{}\".format(output_local_file_path), \"dbfs:{}\".format(output_dbfs_file_path) )\n\nprint('Arquivo copiado de: {} para o diret√≥rio dbfs {}'.format(output_local_file_path, output_dbfs_file_path))"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["##Ler o arquivo .csv em um Spark DataFrame\nPor quest√µes de performance, vamos ler o arquivo .csv utilizando um [DataFrame do Spark](https://spark.apache.org/docs/latest/sql-programming-guide.html).\n\nUtilizaremos as segmentos op√ß√µes: <br/>\n<br/>\n* format: CSV\n* inferSchema: true / Permite que os tipos de dados sejam automaticamente inferidos\n* header: true / Primeira linha ser√° entendida como o cabe√ßalho\n* sep: \";\" / Ser√° utilizado como delimitador de colunas o car√°cter \";\"\n* load: path / O caminho do arquivo que ser√° carregado"],"metadata":{}},{"cell_type":"code","source":["file_type = \"csv\"\ninfer_schema = \"true\"\nfirst_row_is_header = \"true\"\ndelimiter = \";\"\n\ncarros_usados = spark.read.format(file_type) \\\n                     .option(\"inferSchema\", infer_schema) \\\n                     .option(\"header\", first_row_is_header) \\\n                     .option(\"sep\", delimiter) \\\n                     .load(output_dbfs_file_path)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["## Visualiza√ß√£o dos Dados\n\nA tabela de carros usados possui os seguintes campos:<br/>\n<br/>\n* **PRECO**: Pre√ßo de venda do ve√≠culo (vari√°vel target / previs√£o)\n* **IDADE_ANOS**: N√∫mero de anos desde a data de fabrica√ß√£o do ve√≠culo\n* **KM**: N√∫mero de kilometros rodados pelo ve√≠culo\n* **TIPO_COMBUSTIVEL**: Tipo de combust√≠vel utilizado\n* **[HP](https://en.wikipedia.org/wiki/Horsepower)**: Medida de pot√™ncia do ve√≠culo\n* **COR_METALICA**: Indica se o ve√≠culo possui cor met√°lica (1 para sim e 0 para n√£o). Pode indicar maior valoriza√ß√£o\n* **AUTOMATICO**: Indica se o ve√≠culo √© autom√°tico (1 para sim e 0 para n√£o)\n* **[CC](https://pt.wikipedia.org/wiki/Cilindrada)**: Cilindradas do ve√≠culo\n* **QTD_PORTAS**: N√∫mero de portas do ve√≠culo\n* **PESO_KG**: Peso em quilograma do ve√≠culo\n\nCom o comando `display(carros_usados)` podemos analisar o DataFrame"],"metadata":{}},{"cell_type":"code","source":["carros_usados.show(n=5)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["Com o [Azure Databricks](https://azure.microsoft.com/pt-br/services/databricks/) assim que executamos o Display do DataFrame podemos na pr√≥pria c√©lula indicar os tipos de gr√°ficos que queremos visualizar (clicando no icone gr√°fico abaixo do DataFrame e em `PlotOptions`).\n\nAbaixo √© poss√≠vel com o comando `Display` exibir uma visualiza√ß√£o por Tipo de Combust√≠vel e Pre√ßo (utilizando 30 `bins` [n√∫mero de colunas] ) alterando-se o `Plot Options` (somente dispon√≠vel para Azure Databricks)."],"metadata":{}},{"cell_type":"code","source":["#display(carros_usados)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["Tamb√©m podemos utilizar outras bibliotecas para an√°lise gr√°fica como o `matplotlib` ou `seaborn`. Neste caso pode-se converter o DataFrame Spark para um DataFrame Pandas (com isso a performance pode ser degradada).\n\nAbaixo um [histograma](https://pt.wikipedia.org/wiki/Histograma) gerado a partir do pre√ßo de venda do ve√≠culo utilizando o matplotlib a partir de um [DataFrame do Pandas](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)."],"metadata":{}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n%matplotlib inline \n\ndisplay(carros_usados.toPandas().plot(kind='hist', y='PRECO'))"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["# Criando uma regress√£o linear simples"],"metadata":{}},{"cell_type":"markdown","source":["Podemos iniciar investigando se a idade do ve√≠culo pode influenciar seu pre√ßo de venda."],"metadata":{}},{"cell_type":"code","source":["carros_usados_pd = carros_usados.toPandas()\n\nfig, ax = plt.subplots()\n\n# Populate the figure\nplt.scatter(carros_usados_pd['IDADE_ANOS'], carros_usados_pd['PRECO'])\n\n# Set various labels\nplt.title('Pre√ßo dos carros usados como uma fun√ß√£o da idade')\nplt.ylabel('Pre√ßo [R$]')\nplt.xlabel('Idade [Meses]')\n\n# Extras?\nplt.grid() # Turn plot-grid on\n\n# Show figure\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":["Repare que quanto maior a idade do ve√≠culo menor o seu pre√ßo de venda (make sense??).\n\nGeralmente quando falamos em Machine Learning (aprendizado de m√°quina) estamos pensando em uma tarefa espec√≠fica. No nosso caso, a tarefa b√°sica \n√© a de **prever o pre√ßo de venda de um ve√≠culo** utilizando para isso dados hist√≥ricos de vendas de outros ve√≠culos.\n\nRegress√£o Linear √© uma das primeiras t√©cnicas estat√≠sticas aprendidas para previs√£o de dados que se comportam de forma linear üôÑ. <br/><br/>\nE o que isso significa ? Basicamente estamos falando que quando uma vari√°vel cresce (ou diminui) outra vari√°vel tamb√©m t√™m o mesmo comportamento, como por exemplo, o **PRE√áO** do ve√≠culo com a sua **IDADE** em meses (que acabamos de analisar de forma gr√°fica).\n\nEste comportamento, para os mais entendidos, √© feito atrav√©s da famosa equa√ß√£o \\\\(y = ax + b\\\\).\n\nNo exemplo dado estamos falando apenas na rela√ß√£o de duas vari√°veis (PRE√áO e IDADE), por√©m a ideia √© utilizar diferentes vari√°veis no mesmo modelo linear.\n\nNeste tipo de situa√ß√£o (que √© a mais comum) a visualiza√ß√£o √© mais complexa pois a previs√£o n√£o se dar√° por uma √∫nica reta (mas sim por hiperplanos üò≥). Quem quiser entender mais sobre isso, recomendo o v√≠deo [Regress√£o Linear M√∫ltipla](https://drive.google.com/file/d/1MKIO-oe8mtz92rlZp3eZJIYVmQSpW0Pi/view) de uma aula dada no IME/USP sobre o assunto."],"metadata":{}},{"cell_type":"markdown","source":["## Tratamento dos dados\nAntes de aplicarmos um modelo de Regress√£o Linear precisamos primeiramente tratar os dados que ser√£o ENTRADA do modelo, isto √©, precisaremos limpar, padronizar e enriquecer os dados que ser√£o utilizados para treinamento do modelo."],"metadata":{}},{"cell_type":"code","source":["carros_usados.show(n=5)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":["O primeiro ponto importante √© analisarmos se existem valores faltantes para cada uma das colunas que ser√£o utilizadas no modelo. \n\nRepare que existem valores `null` (faltantes) no conjunto de dados analisado. Podemos checar estes valores atrav√©s do comando abaixo:"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql.functions import isnan, when, col\n\nfor c in carros_usados.columns:\n  carros_usados.where(col(c).isNull()).show()"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":["Existem diversas t√©cnicas de tratamento de valores faltantes (substitui√ß√£o pela m√©dia, moda, etc). Para simplificarmos, o processo vamos simplesmente remover toda a linha em que seja encontrado algum valor faltante."],"metadata":{}},{"cell_type":"code","source":["carros_usados = carros_usados.na.drop()"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":["Outro ponto importante √© analisarmos o *TIPO* das vari√°veis de entrada. Repare que a vari√°vel **TIPO_COMBUSTIVEL** √© uma vari√°vel categ√≥rica em formato TEXTO e quando falamos em modelos de aprendizado de m√°quina precisamos que todas as vari√°veis de *INPUT* sejam de alguma forma retratadas de forma num√©rica. Desta forma, o modelo (que nada mais √© do que uma express√£o matem√°tica, muitas vezes extremamente complexa) conseguir√° utilizar os dados de forma apropriada."],"metadata":{}},{"cell_type":"markdown","source":["Para tratamento da vari√°vel utilizaremos as t√©cnicas `StringIndexer` e `OneHotEncoder` que permitem representar as var√≠aveis categ√≥ricas em um formato vetorial bin√°rio. \n\nCom a `StringIndexer` representaremos as var√≠aveis categ√≥ricas de forma num√©rica (ex: GASOLINA=0, DIESEL=1, etc)."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import StringIndexer, OneHotEncoderEstimator, VectorAssembler\n\nindexer = StringIndexer(inputCol='TIPO_COMBUSTIVEL', outputCol='TIPO_COMBUSTIVEL_index')\nindexed = indexer.fit(carros_usados).transform(carros_usados)\nindexed.show()"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":["Repare que foi adicionada uma nova coluna chamada **TIPO_COMBUSTIVEL_index** com a representa√ß√£o num√©rica mencionada.\n\nTamb√©m vamos utilizar a t√©cnica de `OneHotEncoder` para transforma√ß√£o vetorial bin√°ria da vari√°vel que foi indexada (uma lista mais completa das t√©cnicas pode ser encontrada no [link](https://spark.apache.org/docs/latest/ml-features.html) ). Para otimiza√ß√£o deste processo ainda n√£o vamos executar as transforma√ß√µes, vamos criar `Stages` (est√°gios de processamento das transforma√ß√µes) que ser√£o posteriormente colocadas em um `Pipeline`)."],"metadata":{}},{"cell_type":"code","source":["encoder = OneHotEncoderEstimator(inputCols=[\"TIPO_COMBUSTIVEL_index\"],\n                                 outputCols=[\"TIPO_COMBUSTIVEL_vetor\"])\n\nstages = [indexer, encoder]"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":["A vari√°vel `stages` cont√©m os est√°gios de `StringIndexer` e `OneHotEncoder`, al√©m deles utilizaremos tamb√©m a t√©cnica de `VectorAssembler` para consolidar todas as vari√°veis (features) que ser√£o utilizadas para treinamento do modelo e adicionaremos mais este est√°gio na vari√°vel `stages`."],"metadata":{}},{"cell_type":"code","source":["colunas_treino = ['IDADE_ANOS', 'KM', 'HP', 'COR_METALICA', 'AUTOMATICO', 'CC', 'QTD_PORTAS', 'PESO_KG', 'TIPO_COMBUSTIVEL_vetor']\n\nassembler = VectorAssembler(inputCols=colunas_treino, outputCol=\"features\")\nstages += [assembler]"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":["Com os est√°gios de tratamento j√° definidos devemos agora dividir o conjunto de dados entre dados de treino (utilizado para treinar o modelo) e testes (utilizado para avaliar a performance do modelo). Utilizaremos a propor√ß√£o de 80% para treino e 20% para teste."],"metadata":{}},{"cell_type":"code","source":["treino, teste = carros_usados.randomSplit([0.8, 0.2])"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":["Com isso, finalmente üòÜ podemos ent√£o realizar o treinamento de um modelo de Regress√£o Linear Simples.\n\nPara isso vamos adicion√°-lo no [`Pipeline`](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html?highlight=onehotencoder#pyspark.ml.Pipeline) em conjunto com os outros est√°gios de tratamento de dados."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.regression import LinearRegression\nfrom pyspark.ml import Pipeline\n\nlr = LinearRegression(featuresCol = 'features', labelCol='PRECO')\nstages += [lr]\n \npartialPipeline = Pipeline().setStages(stages)\nmodel = partialPipeline.fit(treino)"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":["##Persistir o modelo\n\nPara ser poss√≠vel a reutiliza√ß√£o do modelo treinado podemos persisti-lo para que possa ser carregado posteriormente (sem a necessidade de re-treinamento)."],"metadata":{}},{"cell_type":"markdown","source":["Na Azure podemos utilizar o [ADLS (Azure Data Lake Storage)](https://azure.microsoft.com/en-us/services/storage/data-lake-storage/) para persistir os modelos gerados em containers criados no Data Lake. Para isso, podemos \"montar\" o container utilizando uma chave de criptografia, fazendo com que o ADLS apare√ßa como uma nova pasta no Databricks. No [link](https://github.com/lfbraz/azure-databricks/blob/master/notebooks/read-from-adls.ipynb) temos mais explica√ß√µes de como realizar este processo. \n\nNeste tutorial vamos persistir o modelo para um diret√≥rio previamente montado. Caso voc√™ n√£o esteja utilizando o Databricks, basta utilizar um diret√≥rio local (ou equivalente a plataforma que estiver utilizando)."],"metadata":{}},{"cell_type":"code","source":["CAMINHO_MODELO = '/mnt/models/modelo-regressao-carros-usados'\n\n# Delete file (if exists)\ndbutils.fs.rm(CAMINHO_MODELO, True)\n\n# Persist model\nmodel.save(CAMINHO_MODELO)"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"markdown","source":["Agora podemos tamb√©m utilizar o modelo para fazer as predi√ß√µes na base de teste"],"metadata":{}},{"cell_type":"markdown","source":["## Predi√ß√µes na base TESTE"],"metadata":{}},{"cell_type":"code","source":["predicoes = model.transform(teste)\n\npredicoes.show(n=5)"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":["## Podemos tamb√©m analisar os resultados das predi√ß√µes\n\nCom o modelo treinado e as predi√ß√µes realizadas, vamos analisar a m√©trica de Erro quadr√°tico m√©dio [RSME](https://en.wikipedia.org/wiki/Root-mean-square_deviation)."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.evaluation import RegressionEvaluator\n\n\nevaluator = RegressionEvaluator(labelCol=\"PRECO\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = evaluator.evaluate(predicoes)\n\nprint(\"RMSE na base TESTE = %g\" % rmse)"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"markdown","source":["### Podemos comparar graficamente o \"ERRO\" das predi√ß√µes realizadas com rela√ß√£o ao valor real de PRE√áO."],"metadata":{}},{"cell_type":"code","source":["from sklearn import metrics\n\nfig, ax = plt.subplots()\n\ny_pred = predicoes.toPandas().prediction\ny_test = predicoes.toPandas().PRECO\n\n# Make a list of all the errors in the test-dataset:\nerrors = (y_pred - y_test)\n\n### Populate the figure\n# Plot the test-data:\nplt.scatter(teste.toPandas().PRECO, errors, color='red', edgecolors='black')\n\n# Set various labels\nplt.ylabel('ERROS')\nplt.xlabel('PRE√áO')\n\nplt.title('Erros em $ por Pre√ßo')\n\n# Extras?\nplt.grid() # Turn plot-grid on\nplt.legend()\n\n# Show figure\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":43}],"metadata":{"name":"ml-modelo-regressao-carros-usados","notebookId":1148180762024892},"nbformat":4,"nbformat_minor":0}